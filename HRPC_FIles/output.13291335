Fri Nov 27 20:52:33 2020       
+-----------------------------------------------------------------------------+
| NVIDIA-SMI 440.95.01    Driver Version: 440.95.01    CUDA Version: 10.2     |
|-------------------------------+----------------------+----------------------+
| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |
| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |
|===============================+======================+======================|
|   0  Tesla K20m          On   | 00000000:20:00.0 Off |                    0 |
| N/A   22C    P8    25W / 225W |     58MiB /  4743MiB |      0%      Default |
+-------------------------------+----------------------+----------------------+
|   1  Tesla K20m          On   | 00000000:8B:00.0 Off |                    0 |
| N/A   16C    P8    16W / 225W |     56MiB /  4743MiB |      0%      Default |
+-------------------------------+----------------------+----------------------+
                                                                               
+-----------------------------------------------------------------------------+
| Processes:                                                       GPU Memory |
|  GPU       PID   Type   Process name                             Usage      |
|=============================================================================|
|    0     10452      G   /usr/bin/Xorg                                 45MiB |
|    1     10452      G   /usr/bin/Xorg                                 43MiB |
+-----------------------------------------------------------------------------+
TEST 1 LUStage15.exe
LUStage15.cu(281): warning: conversion from a string literal to "char *" is deprecated

LUStage15.cu(295): warning: conversion from a string literal to "char *" is deprecated

LUStage15.cu(319): warning: conversion from a string literal to "char *" is deprecated

LUStage15.cu(327): warning: conversion from a string literal to "char *" is deprecated

LUStage15.cu(443): warning: conversion from a string literal to "char *" is deprecated

LUStage15.cu(457): warning: expression has no effect

LUStage15.cu(459): warning: conversion from a string literal to "char *" is deprecated

LUStage15.cu(481): warning: conversion from a string literal to "char *" is deprecated

LUStage15.cu(524): warning: expression has no effect

LUStage15.cu(526): warning: conversion from a string literal to "char *" is deprecated

LUStage15.cu(549): warning: conversion from a string literal to "char *" is deprecated

LUStage15.cu(589): warning: statement is unreachable

LUStage15.cu(654): warning: conversion from a string literal to "char *" is deprecated

LUStage15.cu(657): warning: conversion from a string literal to "char *" is deprecated

LUStage15.cu(281): warning: conversion from a string literal to "char *" is deprecated

LUStage15.cu(295): warning: conversion from a string literal to "char *" is deprecated

LUStage15.cu(319): warning: conversion from a string literal to "char *" is deprecated

LUStage15.cu(327): warning: conversion from a string literal to "char *" is deprecated

LUStage15.cu(443): warning: conversion from a string literal to "char *" is deprecated

LUStage15.cu(457): warning: expression has no effect

LUStage15.cu(459): warning: conversion from a string literal to "char *" is deprecated

LUStage15.cu(481): warning: conversion from a string literal to "char *" is deprecated

LUStage15.cu(524): warning: expression has no effect

LUStage15.cu(526): warning: conversion from a string literal to "char *" is deprecated

LUStage15.cu(549): warning: conversion from a string literal to "char *" is deprecated

LUStage15.cu(589): warning: statement is unreachable

LUStage15.cu(654): warning: conversion from a string literal to "char *" is deprecated

LUStage15.cu(657): warning: conversion from a string literal to "char *" is deprecated

------------------------------------------------------------
Number of GPU devices found = 2
[Device: 0] Compute Capability 3.5.
 ... multiprocessor count  = 13
 ... max threads per multiprocessor = 2048
 ... max threads per block = 1024
 ... max block dimension   = 1024, 1024, 64 (along x, y, z)
 ... max grid size         = 2147483647, 65535, 65535 (along x, y, z)
 ... warp size             = 32
 ... clock rate            = 705 MHz
[Device: 1] Compute Capability 3.5.
 ... multiprocessor count  = 13
 ... max threads per multiprocessor = 2048
 ... max threads per block = 1024
 ... max block dimension   = 1024, 1024, 64 (along x, y, z)
 ... max grid size         = 2147483647, 65535, 65535 (along x, y, z)
 ... warp size             = 32
 ... clock rate            = 705 MHz
------------------------------------------------------------
GPU has created 35 streams


Complete test for Matrix size 200 X 200
CPU Begins:
Computing LU a 200 X 200 matrix by CPU took: 3.388 ms
GPU Begins:
1) Copying a 200 X 200 matrix (# bytes: 160000) from RAM to GPU: took 0.155424ms
2) Computing LU for 200 X 200 matrix by #thread/block: 256 and Shared Memory Size: 256 float: GPU took 36.432320ms
3) Copying a 200 X 200 matrix (# bytes: 160000) from GPU to RAM: took 0.082816 ms
Comparing Result:
Lower Matrix Match? true
Upper Matrix Match? true


Complete test for Matrix size 1500 X 1500
CPU Begins:
Computing LU a 1500 X 1500 matrix by CPU took: 379.114 ms
GPU Begins:
1) Copying a 1500 X 1500 matrix (# bytes: 9000000) from RAM to GPU: took 2.860896ms
2) Computing LU for 1500 X 1500 matrix by #thread/block: 256 and Shared Memory Size: 256 float: GPU took 1112.998291ms
3) Copying a 1500 X 1500 matrix (# bytes: 9000000) from GPU to RAM: took 2.355136 ms
Comparing Result:
Lower Matrix Match? false
Upper Matrix Match? false
TEST 2 LUStage16.exe
LUStage16.cu(255): warning: conversion from a string literal to "char *" is deprecated

LUStage16.cu(269): warning: conversion from a string literal to "char *" is deprecated

LUStage16.cu(264): warning: variable "nColumnForMemoryRead" was declared but never referenced

LUStage16.cu(278): warning: conversion from a string literal to "char *" is deprecated

LUStage16.cu(293): warning: conversion from a string literal to "char *" is deprecated

LUStage16.cu(301): warning: conversion from a string literal to "char *" is deprecated

LUStage16.cu(415): warning: conversion from a string literal to "char *" is deprecated

LUStage16.cu(431): warning: expression has no effect

LUStage16.cu(433): warning: conversion from a string literal to "char *" is deprecated

LUStage16.cu(456): warning: conversion from a string literal to "char *" is deprecated

LUStage16.cu(497): warning: expression has no effect

LUStage16.cu(499): warning: conversion from a string literal to "char *" is deprecated

LUStage16.cu(522): warning: conversion from a string literal to "char *" is deprecated

LUStage16.cu(624): warning: conversion from a string literal to "char *" is deprecated

LUStage16.cu(627): warning: conversion from a string literal to "char *" is deprecated

LUStage16.cu(255): warning: conversion from a string literal to "char *" is deprecated

LUStage16.cu(269): warning: conversion from a string literal to "char *" is deprecated

LUStage16.cu(278): warning: conversion from a string literal to "char *" is deprecated

LUStage16.cu(293): warning: conversion from a string literal to "char *" is deprecated

LUStage16.cu(301): warning: conversion from a string literal to "char *" is deprecated

LUStage16.cu(415): warning: conversion from a string literal to "char *" is deprecated

LUStage16.cu(431): warning: expression has no effect

LUStage16.cu(433): warning: conversion from a string literal to "char *" is deprecated

LUStage16.cu(456): warning: conversion from a string literal to "char *" is deprecated

LUStage16.cu(497): warning: expression has no effect

LUStage16.cu(499): warning: conversion from a string literal to "char *" is deprecated

LUStage16.cu(522): warning: conversion from a string literal to "char *" is deprecated

LUStage16.cu(624): warning: conversion from a string literal to "char *" is deprecated

LUStage16.cu(627): warning: conversion from a string literal to "char *" is deprecated

------------------------------------------------------------
Number of GPU devices found = 2
[Device: 0] Compute Capability 3.5.
 ... multiprocessor count  = 13
 ... max threads per multiprocessor = 2048
 ... max threads per block = 1024
 ... max block dimension   = 1024, 1024, 64 (along x, y, z)
 ... max grid size         = 2147483647, 65535, 65535 (along x, y, z)
 ... warp size             = 32
 ... clock rate            = 705 MHz
[Device: 1] Compute Capability 3.5.
 ... multiprocessor count  = 13
 ... max threads per multiprocessor = 2048
 ... max threads per block = 1024
 ... max block dimension   = 1024, 1024, 64 (along x, y, z)
 ... max grid size         = 2147483647, 65535, 65535 (along x, y, z)
 ... warp size             = 32
 ... clock rate            = 705 MHz
------------------------------------------------------------
GPU has created 35 streams


Complete test for Matrix size 200 X 200
CPU Begins:
Computing LU a 200 X 200 matrix by CPU took: 3.376 ms
GPU Begins:
1) Copying a 200 X 200 matrix (# bytes: 160000) from RAM to GPU: took 0.171552ms
2) Computing LU for 200 X 200 matrix by #thread/block: 256 and Shared Memory Size: 25 float: GPU took 16.211329ms
3) Copying a 200 X 200 matrix (# bytes: 160000) from GPU to RAM: took 0.082112 ms
Comparing Result:
Lower Matrix Match? true
Upper Matrix Match? true


Complete test for Matrix size 1500 X 1500
CPU Begins:
Computing LU a 1500 X 1500 matrix by CPU took: 869.678 ms
GPU Begins:
1) Copying a 1500 X 1500 matrix (# bytes: 9000000) from RAM to GPU: took 2.843072ms
2) Computing LU for 1500 X 1500 matrix by #thread/block: 256 and Shared Memory Size: 25 float: GPU took 1037.564575ms
3) Copying a 1500 X 1500 matrix (# bytes: 9000000) from GPU to RAM: took 2.352256 ms
Comparing Result:
Lower Matrix Match? true
Upper Matrix Match? true

Timing test for Matrix size 100 X 100
Computing LU for 100 X 100 matrix by #thread/block: 256 and Shared Memory Size: 25 float: GPU took 5.941984ms
Computing LU for 100 X 100 matrix by #thread/block: 256 and Shared Memory Size: 25 float: GPU took 5.854336ms
Computing LU for 100 X 100 matrix by #thread/block: 256 and Shared Memory Size: 25 float: GPU took 5.843904ms

Timing test for Matrix size 500 X 500
Computing LU for 500 X 500 matrix by #thread/block: 256 and Shared Memory Size: 25 float: GPU took 75.943459ms
Computing LU for 500 X 500 matrix by #thread/block: 256 and Shared Memory Size: 25 float: GPU took 75.647362ms
Computing LU for 500 X 500 matrix by #thread/block: 256 and Shared Memory Size: 25 float: GPU took 75.145729ms

Timing test for Matrix size 1000 X 1000
Computing LU for 1000 X 1000 matrix by #thread/block: 256 and Shared Memory Size: 25 float: GPU took 361.612915ms
Computing LU for 1000 X 1000 matrix by #thread/block: 256 and Shared Memory Size: 25 float: GPU took 362.261017ms
Computing LU for 1000 X 1000 matrix by #thread/block: 256 and Shared Memory Size: 25 float: GPU took 361.114166ms

Timing test for Matrix size 2000 X 2000
Computing LU for 2000 X 2000 matrix by #thread/block: 256 and Shared Memory Size: 25 float: GPU took 2271.953857ms
Computing LU for 2000 X 2000 matrix by #thread/block: 256 and Shared Memory Size: 25 float: GPU took 2275.671387ms
Computing LU for 2000 X 2000 matrix by #thread/block: 256 and Shared Memory Size: 25 float: GPU took 2274.367188ms
GPU has released 35 streams

------------------------------------------------------------
Sender: LSF System <lsfadmin@gpu64-3001>
Subject: Job 13291335: <GPUStage15> in cluster <Main_Compute> Done

Job <GPUStage15> was submitted from host <login7> by user <alireza.safdari> in cluster <Main_Compute>.
Job was executed on host(s) <20*gpu64-3001>, in queue <sn_short>, as user <alireza.safdari> in cluster <Main_Compute>.
</home/alireza.safdari> was used as the home directory.
</scratch/user/alireza.safdari> was used as the working directory.
Started at Fri Nov 27 20:52:27 2020
Results reported on Fri Nov 27 20:52:58 2020

Your job looked like:

------------------------------------------------------------
# LSBATCH: User input
#BSUB -n 20 -R 'select[gpu] rusage[mem=2000] span[ptile=20]' -M 20000
#BSUB -J GPUStage15 -o output.%J -L /bin/bash -W 0:30
##
##NECESSARY JOB SPECIFICATIONS
##BSUB -J JobName             # Set the job name to "JobName"
##BSUB -L /bin/bash           # Uses the bash login shell to initialize the job's execution environment.
##BSUB -W hh:mm               # Sets job's runtime wall-clock limit in hours:minutes or just minutes (-mm)
##BSUB -n NNN                 # NNN: total number of cores/jobslots to allocate for the job
##BSUB -R "select[node-type]" # Select node-type: nxt, mem256gb, gpu, phi, mem1t, mem2t ...
##BSUB -R "span[ptile=XX]"    # XX:  number of cores/jobslots per node to use. Also, a node selection criterion.
##BSUB -R "rusage[mem=nnn]"   # Reserves nnn MBs per process/CPU for the job
##BSUB -M mm                  # Sets the per process enforceable memory limit to nnn MB
##BSUB -o OUTPUTFILE.%J       # Send stdout and stderr to "OUTPUTFILE.[jobID]"
#
# <--- at this point the current working directory is the one you submitted the job from.
#
module load intel/2017A  CUDA     # load Intel software stack 
#
#

nvidia-smi

echo "TEST 1 LUStage15.exe"
nvcc -arch=compute_35 -code=sm_35 -ccbin=icc -o LUStage15.exe LUStage15.cu -fmad=false
./LUStage15.exe

echo "TEST 2 LUStage16.exe"
nvcc -arch=compute_35 -code=sm_35 -ccbin=icc -o LUStage16.exe LUStage16.cu -fmad=false
./LUStage16.exe
------------------------------------------------------------

Successfully completed.

Resource usage summary:

    CPU time :                                   22.57 sec.
    Max Memory :                                 214 MB
    Average Memory :                             132.40 MB
    Total Requested Memory :                     40000.00 MB
    Delta Memory :                               39786.00 MB
    Max Swap :                                   9 MB
    Max Processes :                              7
    Max Threads :                                9

The output (if any) is above this job summary.

