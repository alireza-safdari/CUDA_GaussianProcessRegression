Fri Nov 27 04:42:46 2020       
+-----------------------------------------------------------------------------+
| NVIDIA-SMI 440.95.01    Driver Version: 440.95.01    CUDA Version: 10.2     |
|-------------------------------+----------------------+----------------------+
| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |
| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |
|===============================+======================+======================|
|   0  Tesla V100-PCIE...  Off  | 00000000:3B:00.0 Off |                    0 |
| N/A   37C    P0    27W / 250W |     12MiB / 32510MiB |      0%      Default |
+-------------------------------+----------------------+----------------------+
|   1  Tesla V100-PCIE...  Off  | 00000000:D8:00.0 Off |                    0 |
| N/A   40C    P0    29W / 250W |     12MiB / 32510MiB |      0%      Default |
+-------------------------------+----------------------+----------------------+
                                                                               
+-----------------------------------------------------------------------------+
| Processes:                                                       GPU Memory |
|  GPU       PID   Type   Process name                             Usage      |
|=============================================================================|
|  No running processes found                                                 |
+-----------------------------------------------------------------------------+
TEST 1 LUStage15.exe
LUStage15.cu(277): warning: conversion from a string literal to "char *" is deprecated

LUStage15.cu(291): warning: conversion from a string literal to "char *" is deprecated

LUStage15.cu(315): warning: conversion from a string literal to "char *" is deprecated

LUStage15.cu(323): warning: conversion from a string literal to "char *" is deprecated

LUStage15.cu(418): warning: conversion from a string literal to "char *" is deprecated

LUStage15.cu(434): warning: expression has no effect

LUStage15.cu(436): warning: conversion from a string literal to "char *" is deprecated

LUStage15.cu(458): warning: conversion from a string literal to "char *" is deprecated

LUStage15.cu(499): warning: expression has no effect

LUStage15.cu(501): warning: conversion from a string literal to "char *" is deprecated

LUStage15.cu(524): warning: conversion from a string literal to "char *" is deprecated

LUStage15.cu(625): warning: conversion from a string literal to "char *" is deprecated

LUStage15.cu(628): warning: conversion from a string literal to "char *" is deprecated

LUStage15.cu(277): warning: conversion from a string literal to "char *" is deprecated

LUStage15.cu(291): warning: conversion from a string literal to "char *" is deprecated

LUStage15.cu(315): warning: conversion from a string literal to "char *" is deprecated

LUStage15.cu(323): warning: conversion from a string literal to "char *" is deprecated

LUStage15.cu(418): warning: conversion from a string literal to "char *" is deprecated

LUStage15.cu(434): warning: expression has no effect

LUStage15.cu(436): warning: conversion from a string literal to "char *" is deprecated

LUStage15.cu(458): warning: conversion from a string literal to "char *" is deprecated

LUStage15.cu(499): warning: expression has no effect

LUStage15.cu(501): warning: conversion from a string literal to "char *" is deprecated

LUStage15.cu(524): warning: conversion from a string literal to "char *" is deprecated

LUStage15.cu(625): warning: conversion from a string literal to "char *" is deprecated

LUStage15.cu(628): warning: conversion from a string literal to "char *" is deprecated

------------------------------------------------------------
Number of GPU devices found = 2
[Device: 0] Compute Capability 7.0.
 ... multiprocessor count  = 80
 ... max threads per multiprocessor = 2048
 ... max threads per block = 1024
 ... max block dimension   = 1024, 1024, 64 (along x, y, z)
 ... max grid size         = 2147483647, 65535, 65535 (along x, y, z)
 ... warp size             = 32
 ... clock rate            = 1380 MHz
[Device: 1] Compute Capability 7.0.
 ... multiprocessor count  = 80
 ... max threads per multiprocessor = 2048
 ... max threads per block = 1024
 ... max block dimension   = 1024, 1024, 64 (along x, y, z)
 ... max grid size         = 2147483647, 65535, 65535 (along x, y, z)
 ... warp size             = 32
 ... clock rate            = 1380 MHz
------------------------------------------------------------
GPU has created 35 streams


Complete test for Matrix size 200 X 200
CPU Begins:
Computing LU a 200 X 200 matrix by CPU took: 1.764 ms
GPU Begins:
1) Copying a 200 X 200 matrix (# bytes: 160000) from RAM to GPU: took 0.133216ms
2) Computing LU for 200 X 200 matrix by #thread/block: 256 and Shared Memory Size: 256 float: GPU took 7.389568ms
3) Copying a 200 X 200 matrix (# bytes: 160000) from GPU to RAM: took 0.062464 ms
Comparing Result:
Lower Matrix Match? false
Upper Matrix Match? false


Complete test for Matrix size 1500 X 1500
CPU Begins:
Computing LU a 1500 X 1500 matrix by CPU took: 345.7 ms
GPU Begins:
1) Copying a 1500 X 1500 matrix (# bytes: 9000000) from RAM to GPU: took 2.098624ms
2) Computing LU for 1500 X 1500 matrix by #thread/block: 256 and Shared Memory Size: 256 float: GPU took 235.222885ms
3) Copying a 1500 X 1500 matrix (# bytes: 9000000) from GPU to RAM: took 1.728288 ms
Comparing Result:
Lower Matrix Match? false
Upper Matrix Match? false

Timing test for Matrix size 200 X 200
Computing LU for 200 X 200 matrix by #thread/block: 256 and Shared Memory Size: 256 float: GPU took 6.868192ms
Computing LU for 200 X 200 matrix by #thread/block: 256 and Shared Memory Size: 256 float: GPU took 6.877472ms
Computing LU for 200 X 200 matrix by #thread/block: 256 and Shared Memory Size: 256 float: GPU took 6.819328ms

Timing test for Matrix size 500 X 500
Computing LU for 500 X 500 matrix by #thread/block: 256 and Shared Memory Size: 256 float: GPU took 42.061790ms
Computing LU for 500 X 500 matrix by #thread/block: 256 and Shared Memory Size: 256 float: GPU took 42.010880ms
Computing LU for 500 X 500 matrix by #thread/block: 256 and Shared Memory Size: 256 float: GPU took 41.514721ms

Timing test for Matrix size 1000 X 1000
Computing LU for 1000 X 1000 matrix by #thread/block: 256 and Shared Memory Size: 256 float: GPU took 117.794334ms
Computing LU for 1000 X 1000 matrix by #thread/block: 256 and Shared Memory Size: 256 float: GPU took 117.831421ms
Computing LU for 1000 X 1000 matrix by #thread/block: 256 and Shared Memory Size: 256 float: GPU took 117.642723ms

Timing test for Matrix size 2000 X 2000
Computing LU for 2000 X 2000 matrix by #thread/block: 256 and Shared Memory Size: 256 float: GPU took 397.471741ms
Computing LU for 2000 X 2000 matrix by #thread/block: 256 and Shared Memory Size: 256 float: GPU took 398.051788ms
Computing LU for 2000 X 2000 matrix by #thread/block: 256 and Shared Memory Size: 256 float: GPU took 397.733398ms
GPU has released 35 streams
TEST 2 LUStage16.exe
LUStage16.cu(251): warning: conversion from a string literal to "char *" is deprecated

LUStage16.cu(265): warning: conversion from a string literal to "char *" is deprecated

LUStage16.cu(260): warning: variable "nColumnForMemoryRead" was declared but never referenced

LUStage16.cu(274): warning: conversion from a string literal to "char *" is deprecated

LUStage16.cu(289): warning: conversion from a string literal to "char *" is deprecated

LUStage16.cu(297): warning: conversion from a string literal to "char *" is deprecated

LUStage16.cu(392): warning: conversion from a string literal to "char *" is deprecated

LUStage16.cu(408): warning: expression has no effect

LUStage16.cu(410): warning: conversion from a string literal to "char *" is deprecated

LUStage16.cu(433): warning: conversion from a string literal to "char *" is deprecated

LUStage16.cu(474): warning: expression has no effect

LUStage16.cu(476): warning: conversion from a string literal to "char *" is deprecated

LUStage16.cu(499): warning: conversion from a string literal to "char *" is deprecated

LUStage16.cu(598): warning: conversion from a string literal to "char *" is deprecated

LUStage16.cu(601): warning: conversion from a string literal to "char *" is deprecated

LUStage16.cu(251): warning: conversion from a string literal to "char *" is deprecated

LUStage16.cu(265): warning: conversion from a string literal to "char *" is deprecated

LUStage16.cu(274): warning: conversion from a string literal to "char *" is deprecated

LUStage16.cu(289): warning: conversion from a string literal to "char *" is deprecated

LUStage16.cu(297): warning: conversion from a string literal to "char *" is deprecated

LUStage16.cu(392): warning: conversion from a string literal to "char *" is deprecated

LUStage16.cu(408): warning: expression has no effect

LUStage16.cu(410): warning: conversion from a string literal to "char *" is deprecated

LUStage16.cu(433): warning: conversion from a string literal to "char *" is deprecated

LUStage16.cu(474): warning: expression has no effect

LUStage16.cu(476): warning: conversion from a string literal to "char *" is deprecated

LUStage16.cu(499): warning: conversion from a string literal to "char *" is deprecated

LUStage16.cu(598): warning: conversion from a string literal to "char *" is deprecated

LUStage16.cu(601): warning: conversion from a string literal to "char *" is deprecated

------------------------------------------------------------
Number of GPU devices found = 2
[Device: 0] Compute Capability 7.0.
 ... multiprocessor count  = 80
 ... max threads per multiprocessor = 2048
 ... max threads per block = 1024
 ... max block dimension   = 1024, 1024, 64 (along x, y, z)
 ... max grid size         = 2147483647, 65535, 65535 (along x, y, z)
 ... warp size             = 32
 ... clock rate            = 1380 MHz
[Device: 1] Compute Capability 7.0.
 ... multiprocessor count  = 80
 ... max threads per multiprocessor = 2048
 ... max threads per block = 1024
 ... max block dimension   = 1024, 1024, 64 (along x, y, z)
 ... max grid size         = 2147483647, 65535, 65535 (along x, y, z)
 ... warp size             = 32
 ... clock rate            = 1380 MHz
------------------------------------------------------------
GPU has created 35 streams


Complete test for Matrix size 200 X 200
CPU Begins:
Computing LU a 200 X 200 matrix by CPU took: 2.141 ms
GPU Begins:
1) Copying a 200 X 200 matrix (# bytes: 160000) from RAM to GPU: took 0.132864ms
2) Computing LU for 200 X 200 matrix by #thread/block: 256 and Shared Memory Size: 25 float: GPU took 5.353536ms
3) Copying a 200 X 200 matrix (# bytes: 160000) from GPU to RAM: took 0.060608 ms
Comparing Result:
Lower Matrix Match? false
Upper Matrix Match? false


Complete test for Matrix size 1500 X 1500
CPU Begins:
Computing LU a 1500 X 1500 matrix by CPU took: 342.668 ms
GPU Begins:
1) Copying a 1500 X 1500 matrix (# bytes: 9000000) from RAM to GPU: took 2.128256ms
2) Computing LU for 1500 X 1500 matrix by #thread/block: 256 and Shared Memory Size: 25 float: GPU took 651.743286ms
3) Copying a 1500 X 1500 matrix (# bytes: 9000000) from GPU to RAM: took 1.688992 ms
Comparing Result:
Lower Matrix Match? false
Upper Matrix Match? false

Timing test for Matrix size 200 X 200
Computing LU for 200 X 200 matrix by #thread/block: 256 and Shared Memory Size: 25 float: GPU took 5.075232ms
Computing LU for 200 X 200 matrix by #thread/block: 256 and Shared Memory Size: 25 float: GPU took 5.021760ms
Computing LU for 200 X 200 matrix by #thread/block: 256 and Shared Memory Size: 25 float: GPU took 5.014784ms

Timing test for Matrix size 500 X 500
Computing LU for 500 X 500 matrix by #thread/block: 256 and Shared Memory Size: 25 float: GPU took 34.767426ms
Computing LU for 500 X 500 matrix by #thread/block: 256 and Shared Memory Size: 25 float: GPU took 34.794209ms
Computing LU for 500 X 500 matrix by #thread/block: 256 and Shared Memory Size: 25 float: GPU took 34.715679ms

Timing test for Matrix size 1000 X 1000
Computing LU for 1000 X 1000 matrix by #thread/block: 256 and Shared Memory Size: 25 float: GPU took 210.659195ms
Computing LU for 1000 X 1000 matrix by #thread/block: 256 and Shared Memory Size: 25 float: GPU took 211.406815ms
Computing LU for 1000 X 1000 matrix by #thread/block: 256 and Shared Memory Size: 25 float: GPU took 211.101532ms

Timing test for Matrix size 2000 X 2000
Computing LU for 2000 X 2000 matrix by #thread/block: 256 and Shared Memory Size: 25 float: GPU took 1486.329224ms
Computing LU for 2000 X 2000 matrix by #thread/block: 256 and Shared Memory Size: 25 float: GPU took 1491.366821ms
Computing LU for 2000 X 2000 matrix by #thread/block: 256 and Shared Memory Size: 25 float: GPU took 1491.879028ms
GPU has released 35 streams

------------------------------------------------------------
Sender: LSF System <lsfadmin@r740-0202>
Subject: Job 13268278: <GPUStage15> in cluster <Main_Compute> Done

Job <GPUStage15> was submitted from host <login2> by user <alireza.safdari> in cluster <Main_Compute>.
Job was executed on host(s) <20*r740-0202>, in queue <v100>, as user <alireza.safdari> in cluster <Main_Compute>.
</home/alireza.safdari> was used as the home directory.
</scratch/user/alireza.safdari> was used as the working directory.
Started at Fri Nov 27 04:42:41 2020
Results reported on Fri Nov 27 04:43:08 2020

Your job looked like:

------------------------------------------------------------
# LSBATCH: User input
#BSUB -n 20 -R 'rusage[mem=2000] span[ptile=20]' -M 20000
#BSUB -J GPUStage15 -o output.%J -L /bin/bash -W 0:30 -q v100 
##
##NECESSARY JOB SPECIFICATIONS
##BSUB -J JobName             # Set the job name to "JobName"
##BSUB -L /bin/bash           # Uses the bash login shell to initialize the job's execution environment.
##BSUB -W hh:mm               # Sets job's runtime wall-clock limit in hours:minutes or just minutes (-mm)
##BSUB -n NNN                 # NNN: total number of cores/jobslots to allocate for the job
##BSUB -R "select[node-type]" # Select node-type: nxt, mem256gb, gpu, phi, mem1t, mem2t ...
##BSUB -R "span[ptile=XX]"    # XX:  number of cores/jobslots per node to use. Also, a node selection criterion.
##BSUB -R "rusage[mem=nnn]"   # Reserves nnn MBs per process/CPU for the job
##BSUB -M mm                  # Sets the per process enforceable memory limit to nnn MB
##BSUB -o OUTPUTFILE.%J       # Send stdout and stderr to "OUTPUTFILE.[jobID]"
#
# <--- at this point the current working directory is the one you submitted the job from.
#
module load intel/2017A  CUDA     # load Intel software stack 
#
#

nvidia-smi

echo "TEST 1 LUStage15.exe"
nvcc -arch=compute_70 -code=sm_70 -ccbin=icc -o LUStage15.exe LUStage15.cu
./LUStage15.exe

echo "TEST 2 LUStage16.exe"
nvcc -arch=compute_70 -code=sm_70 -ccbin=icc -o LUStage16.exe LUStage16.cu
./LUStage16.exe
------------------------------------------------------------

Successfully completed.

Resource usage summary:

    CPU time :                                   17.38 sec.
    Max Memory :                                 226 MB
    Average Memory :                             112.25 MB
    Total Requested Memory :                     40000.00 MB
    Delta Memory :                               39774.00 MB
    Max Processes :                              7
    Max Threads :                                9

The output (if any) is above this job summary.

